{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W1D3_Tutorial1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jMb56P7ZweTX"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/W1D3_anoop_changes/tutorials/W1D3_MLP/W1D3_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2kPrtVyXtaP"
      },
      "source": [
        "\n",
        "# Neuromatch Academy: Week 1, Day 3, Tutorial 1\n",
        "# Name of Day: Name of Tutorial\n",
        "\n",
        "__Content creators:__ Arash Ash\n",
        "\n",
        "\n",
        "\n",
        "__Content reviewers:__ Saeed Salehi, Felix Bartsch, Yu-Fang Yang. \n",
        "\n",
        "__Content editors:__ Gagana B, Spiros Chavlis.\n",
        "\n",
        "__Production editors:__ Anoop Kulkarni, Spiros Chavlis.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2DuJddRXxYY"
      },
      "source": [
        "---\n",
        "# Tutorial objectives\n",
        "In this tutorial, we delve deeper by using one of the most famous deep learning models of all!\n",
        "\n",
        "MLPs are arguably one of the most tractable models that we can use to study deep learning fundamentals. Here we will learn why MLPs are: \n",
        "\n",
        "* similar to biological networks\n",
        "* good at function approximation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aduF74_wPXDQ",
        "cellView": "form"
      },
      "source": [
        "#@markdown Tutorial slides\n",
        "# you should link the slides for all tutorial videos here (we will store pdfs on osf)\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML('<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vSPvHqDTmMq4GyQy6lieNEFxq4qz1SmqC2RNoeei3_niECH53zneh8jJVYOnBIdk0Uaz7y2b9DK8V1t/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"960\" height=\"569\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np4EZarUtKoA"
      },
      "source": [
        "# Recap the experience from last week\n",
        "\n",
        "We focused on linear deep learning last week. We discussed Artificial Neural Networks and saw how it works, the dynamics of learning, and the properties of high dimensional spaces. You should now have some intuition about deep learning systems we will learn. We also dived into PyTorch and autograd, which are tools that make our life easy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEdRnCm2_DT0",
        "cellView": "form"
      },
      "source": [
        "#@title Video 1: Linear DL\n",
        "# Insert the ID of the corresponding youtube video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"xlYttP5C_LY\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtu.be/\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E29pz3hNeQTO"
      },
      "source": [
        "Meet with your pod for 10 minutes to discuss what you learned, what was clear, and what you hope to learn more about."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8nOPFKTuJhA",
        "cellView": "form"
      },
      "source": [
        "#@markdown Tell us your thoughts about what you have learned in week 2.\n",
        "w2_upshot = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh1hjT8_Wleu"
      },
      "source": [
        "# Question of the day"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tdJuZdmMWhGw"
      },
      "source": [
        "#@markdown What functional forms are good or bad for representing complex functions?\n",
        "w3_q = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgOQxVS1X2dB"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXd8Now_XwR7",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "# imports\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.utils import make_grid\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Make sure the Runtime is with None to ensure compatibility\n",
        "dev = \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUyEQpxTSzxe",
        "cellView": "form"
      },
      "source": [
        "# @title Seeding for reproducibility\n",
        "seed = 522\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.use_deterministic_algorithms(True)\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = seed % (worker_id+1)\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj8C2Cf0G0i_",
        "cellView": "form"
      },
      "source": [
        "# @title Dataset download\n",
        "%%capture\n",
        "!rm -r AnimalFaces32x32/\n",
        "!git clone https://github.com/arashash/AnimalFaces32x32\n",
        "!rm -r afhq/\n",
        "!unzip ./AnimalFaces32x32/afhq_32x32.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRrTcZOlXA8C",
        "cellView": "form"
      },
      "source": [
        "# @title Figure settings\n",
        "import ipywidgets as widgets\n",
        "%matplotlib inline \n",
        "fig_w, fig_h = (8, 6)\n",
        "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "my_layout = widgets.Layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Qc7MFcX7Oc",
        "cellView": "form"
      },
      "source": [
        "# @title Helper functions\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis(False)\n",
        "    plt.show()\n",
        "\n",
        "def progress(epoch, loss, epochs=100):\n",
        "    return HTML(\"\"\"\n",
        "        <label for=\"file\">Training loss: {loss}</label>\n",
        "        <progress\n",
        "            value='{epoch}'\n",
        "            max='{epochs}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {epoch}\n",
        "        </progress>\n",
        "    \"\"\".format(loss=loss, epoch=epoch, epochs=epochs))\n",
        "\n",
        "def plot_function_approximation(x, relu_acts, y_hat):\n",
        "  fig, axes = plt.subplots(2, 1)\n",
        "\n",
        "  # Plot ReLU Activations\n",
        "  axes[0].plot(x, relu_acts.T);\n",
        "  axes[0].set(xlabel = 'x', ylabel = 'Activation', title = 'ReLU Activations')\n",
        "  labels = [f'ReLU {i + 1}' for i in range(relu_acts.shape[0])]\n",
        "  axes[0].legend(labels, ncol = 2)\n",
        "\n",
        "  # Plot function approximation\n",
        "  axes[1].plot(x, torch.sin(x), label = 'truth')\n",
        "  axes[1].plot(x, y_hat, label = 'estimated')\n",
        "  axes[1].legend()\n",
        "  axes[1].set(xlabel = 'x', ylabel = 'y(x)', title = 'Function Approximation');\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQGBDFB0yeqV"
      },
      "source": [
        "---\n",
        "# Section 1: Neuron Physiology"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNdeptL-zUnU",
        "cellView": "form"
      },
      "source": [
        "#@title Video 1.1: Overview and Integrate-and-Fire Neurons\n",
        "# Insert the ID of the corresponding youtube video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"exTzHGfEAvU\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtu.be/\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93MxeKdfGN7"
      },
      "source": [
        "## Section 1.1: Leaky Integrate-and-fire (LIF)\n",
        "The basic idea of LIF neuron was proposed in 1907 by Louis Édouard Lapicque, long before we understood the electrophysiology of a neuron (see a translation of [Lapicque's paper](https://pubmed.ncbi.nlm.nih.gov/17968583/) ). More details of the model can be found in the book [**Theoretical neuroscience**](http://www.gatsby.ucl.ac.uk/~dayan/book/) by Peter Dayan and Laurence F. Abbott.\n",
        "\n",
        "The model dynamics is defined with the following formula,\n",
        "\n",
        "$$\n",
        "\\frac{d V}{d t}=\\left\\{\\begin{array}{cc}\n",
        "\\frac{1}{C}\\left(-\\frac{V}{R}+I \\right) & t>t_{r e s t} \\\\\n",
        "0 & \\text { otherwise }\n",
        "\\end{array}\\right.\n",
        "$$\n",
        "\n",
        "Note that $V$, $C$, and $R$ are the membrane voltage, capacitance, and resitance of the neuron respectively and $-\\frac{V}{R}$ is the leakage current. When $I$ is sufficiently strong such that $V$ reaches a certain threshold value $V_{\\rm th}$, it momentarily spikes and then $V$ is reset to $V_{\\rm reset}< V_{\\rm th}$, and voltage stays at $V_{\\rm reset}$ for $\\tau_{\\rm ref}$ ms, mimicking the refractoriness of the neuron during an action potential (note that $V_{\\rm reset}$ and $\\tau_{\\rm ref}$ is assumed to be zero in the lecture):\n",
        "\n",
        "\\begin{eqnarray}\n",
        "V(t)=V_{\\rm reset} \\text{  for } t\\in(t_{\\text{sp}}, t_{\\text{sp}} + \\tau_{\\text{ref}}]\n",
        "\\end{eqnarray}\n",
        "\n",
        "where $t_{\\rm sp}$ is the spike time when $V(t)$ just exceeded $V_{\\rm th}$.\n",
        "\n",
        "Thus, the LIF model captures the facts that a neuron:\n",
        "- performs spatial and temporal integration of synaptic inputs \n",
        "- generates a spike when the voltage reaches a certain threshold\n",
        "- goes refractory during the action potential\n",
        "- has a leaky membrane \n",
        "\n",
        "For in-depth content on computational models of neurons, follow the [NMA](https://www.neuromatchacademy.org/) Week 3 Day 1 material on Real Neurons and specifically this [Tutorial](https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W3D1_RealNeurons/W3D1_Tutorial1.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW9mD1wC11Kw"
      },
      "source": [
        "## Section 1.2: Simulating an LIF Neuron\n",
        "\n",
        "In the cell below is given a function for LIF neuron model with it's arguments described.\n",
        "\n",
        "Note that we will use Euler's method to make a numerical approximation to a derivative. Hence we will use the following implementation of the model dynamics,\n",
        "\n",
        "$$\n",
        "V_n=\\left\\{\\begin{array}{cc}\n",
        "V_{n-1} + \\frac{1}{C}\\left(-\\frac{V}{R}+I \\right) \\Delta t & t>t_{r e s t} \\\\\n",
        "0 & \\text { otherwise }\n",
        "\\end{array}\\right.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FixKcRzqdhf3"
      },
      "source": [
        "def run_LIF(I, T = 50, dt = 0.1, t_rest = 0, tau_ref = 4,\n",
        "            Rm = 1, Cm = 10, Vth = 1, V_spike = 0.5):\n",
        "  \"\"\"\n",
        "  Simulate the LIF dynamics with external input current\n",
        "\n",
        "  Args:\n",
        "    I          : input current (mA)\n",
        "    T          : total time to simulate (msec)\n",
        "    dt         : simulation time step (msec)\n",
        "    t_rest     : initial refractory time\n",
        "    tau_ref    : refractory period (msec)\n",
        "    Rm         : resistance (kOhm)\n",
        "    Cm         : capacitance (uF)\n",
        "    Vth        : spike threshold (V)\n",
        "    V_spike    : spike delta (V)\n",
        "\n",
        "  Returns:\n",
        "    time       : time points\n",
        "    Vm         : membrane potentials\n",
        "  \"\"\"\n",
        "\n",
        "  # Set up array of time steps\n",
        "  time = torch.arange(0, T+dt, dt) \n",
        "  \n",
        "  # Set up array for tracking Vm\n",
        "  Vm = torch.zeros(len(time)) \n",
        "\n",
        "  # Iterate over each time step\n",
        "  for i, t in enumerate(time):\n",
        "\n",
        "    # If t is after refractory period\n",
        "    if t > t_rest:\n",
        "      Vm[i] = Vm[i-1] + 1/Cm*(-Vm[i-1]/Rm + I)  * dt \n",
        "\n",
        "    # If Vm is over the threshold\n",
        "    if Vm[i] >= Vth:\n",
        "\n",
        "      # Increase volatage by change due to spike\n",
        "      Vm[i] += V_spike \n",
        "\n",
        "      # Set up new refactory period\n",
        "      t_rest = t + tau_ref \n",
        "\n",
        "  return time, Vm\n",
        "\n",
        "\n",
        "### Uncomment below to test your function\n",
        "sim_time, Vm = run_LIF(1.5)\n",
        "with plt.xkcd():\n",
        "  plt.plot(sim_time, Vm)\n",
        "  plt.title('LIF Neuron Output')\n",
        "  plt.ylabel('Membrane Potential (V)')\n",
        "  plt.xlabel('Time (msec)')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5hljR2LZXxS"
      },
      "source": [
        "## Section 1.3: Nonlinearity of LIF neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh7Wnzg3ZYaY",
        "cellView": "form"
      },
      "source": [
        "#@title Video 1.3: Are Integrate-and-Fire Neurons Linear?\n",
        "# Insert the ID of the corresponding youtube video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"6IzHZB7xf34\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtu.be/\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw0w47-O6Arl"
      },
      "source": [
        "## Interactive demo: F-I explorer for different $R_m$\n",
        "We know that neurons communicate by modulating the spike count. Therefore it makes sense to characterize their spike count as a function of input current. This is called the neuron's input-output transfer function (so simply F-I curve). Let's plot the neuron's F-I curve and see how it changes with respect to the membrane resistance? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "MPKolg9xjiHW"
      },
      "source": [
        "# @title\n",
        "\n",
        "# @markdown Make sure you execute this cell to enable the widget!\n",
        "\n",
        "@widgets.interact(Rm=widgets.FloatSlider(1., min=0.5, max=10., step=0.1, layout=my_layout))\n",
        "\n",
        "def plot_IF_curve(Rm):\n",
        "  T = 100 # total time to simulate (msec)\n",
        "  dt = 1 # simulation time step (msec)\n",
        "  Vth = 1 # spike threshold (V)\n",
        "  Is = torch.linspace(0, 2, 10)\n",
        "  spike_counts = []\n",
        "  for I in Is:\n",
        "    _, Vm = run_LIF(I, T = T, Vth = Vth, Rm=Rm)\n",
        "    spike_counts += [torch.sum(Vm > Vth)]\n",
        "\n",
        "  plt.plot(Is, spike_counts)\n",
        "  plt.title('LIF Transfer Function (I/F Curve)')\n",
        "  plt.ylabel('Spike count')\n",
        "  plt.xlabel('I (mA)')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adkXbLroqeKc",
        "cellView": "form"
      },
      "source": [
        "#@markdown What happens at infinite membrane potential (Rm)? Why?\n",
        "w3_why_become_relu = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkvnWkvTz2O5"
      },
      "source": [
        "---\n",
        "# Section 2: The Need for MLPs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOgsH7ly5ZU1",
        "cellView": "form"
      },
      "source": [
        "#@title Video 2: The XOR problem\n",
        "# Insert the ID of the corresponding youtube video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"PERmPT1cOP0\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtu.be/\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMJZuSjmsEQV"
      },
      "source": [
        "---\n",
        "## Section 2.1: Universal Function Approximation Theorem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uKiWhgZCSgY",
        "cellView": "form"
      },
      "source": [
        "#@title Video 2.1: Universal Approximation\n",
        "# Insert the ID of the corresponding youtube video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"XXXYxolMVdw\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtu.be/\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS8AGBmqlRNZ"
      },
      "source": [
        "Check out [Lipschitz continuity](https://en.wikipedia.org/wiki/Lipschitz_continuity) for more information about the slide.\n",
        "\n",
        "Now the question is can we approximate any function using multilayer perceptrons?\n",
        "\n",
        " Universal Approximation theorem proves that we can! The intuition behind the theorem is that we can approximate any function sufficiently well, given a sufficient number of basis functions. These basis functions are present in the hidden layer of MLPs.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j2qcuN8x32j"
      },
      "source": [
        "## Exercise 1: Function approximation with ReLU\n",
        "We learned that one hidden layer MLPs are enough to approximate any smooth function! Now let's manually fit a Sine function using ReLU activation. \n",
        "\n",
        "\n",
        "We will approximate the sine function using a linear combination (a weighted sum) of ReLUs with slope 1. We need to determine the bias terms (which determines where the ReLU inflection point from 0 to linear occurs) and how to weight each ReLU. The idea is to set the weights iteratively so that the slope changes in the new sample's direction.\n",
        "\n",
        "First, we generate our \"training data\" from a sine function. These are the points we will use to learn how to approximate the function. We have 10 training data points so we will have 9 ReLUs (we don't need a ReLU for the last data point as we don't have anything to the right of it to model). \n",
        "\n",
        "We first need to figure out the bias term for each ReLU and compute the activation of each ReLU where:\n",
        "\n",
        "$$ y(x) = max(0, x + b) $$\n",
        "\n",
        "We then need to figure out the correct weights on each ReLU so the linear combination approximates the desired function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVSelFbmFIE1"
      },
      "source": [
        "def approximate_function(x_train, y_train):\n",
        "\n",
        "    ####################################################################\n",
        "    # Fill in missing code below (...),\n",
        "    # then remove or comment the line below to test your function\n",
        "    raise NotImplementedError(\"Complete approximate_function!\")\n",
        "    ####################################################################\n",
        "\n",
        "    # Number of relus\n",
        "    n_relus = x_train.shape[0] - 1\n",
        "\n",
        "    # x axis points (more than x train)\n",
        "    x = torch.linspace(torch.min(x_train), torch.max(x_train), 1000)\n",
        "\n",
        "    ## COMPUTE RELU ACTIVATIONS\n",
        "\n",
        "    # First determine what bias terms should be for each of 9 ReLUs\n",
        "    b = ...\n",
        "\n",
        "    # Compute ReLU activations for each point along the x axis (x)\n",
        "    relu_acts = torch.zeros((n_relus, x.shape[0]))\n",
        "\n",
        "    for i_relu in range(n_relus):\n",
        "      relu_acts[i_relu, :] = torch.relu(x + b[i_relu])\n",
        "\n",
        "    ## COMBINE RELU ACTIVATIONS\n",
        "\n",
        "    # Set up weights for weighted sum of ReLUs\n",
        "    combination_weights = torch.zeros((n_relus, ))\n",
        "\n",
        "    # Figure out weights on each ReLU\n",
        "    prev_slope = 0\n",
        "    for i in range(n_relus):\n",
        "      delta_x = x_train[i+1] - x_train[i]\n",
        "      slope = (y_train[i+1] - y_train[i]) / delta_x \n",
        "      combination_weights[i] = ...\n",
        "      prev_slope = slope\n",
        "\n",
        "    # Get output of weighted sum of ReLU activations for every point along x axis\n",
        "    y_hat = ...\n",
        "\n",
        "    return y_hat, relu_acts, x\n",
        "\n",
        "# Make training data from sine function\n",
        "N_train = 10\n",
        "x_train = torch.linspace(0, 2*np.pi, N_train).view(-1, 1)\n",
        "y_train = torch.sin(x_train)\n",
        "\n",
        "\n",
        "### uncomment the lines below to test your function approximation\n",
        "# y_hat, relu_acts, x = approximate_function(x_train, y_train)\n",
        "# plot_function_approximation(x, relu_acts, y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIv9uGAD1BAr"
      },
      "source": [
        "# to_remove solution\n",
        "\n",
        "def approximate_function(x_train, y_train):\n",
        "\n",
        "    # Number of relus\n",
        "    n_relus = x_train.shape[0] - 1\n",
        "\n",
        "    # x axis points (more than x train)\n",
        "    x = torch.linspace(torch.min(x_train), torch.max(x_train), 1000)\n",
        "\n",
        "    ## COMPUTE RELU ACTIVATIONS\n",
        "\n",
        "    # First determine what bias terms should be for each of 9 ReLUs\n",
        "    b = -x_train[:9]\n",
        "\n",
        "    # Compute ReLU activations for each point along the x axis (x)\n",
        "    relu_acts = torch.zeros((n_relus, x.shape[0]))\n",
        "\n",
        "    for i_relu in range(n_relus):\n",
        "      relu_acts[i_relu, :] = torch.relu(x + b[i_relu])\n",
        "\n",
        "\n",
        "    ## COMBINE RELU ACTIVATIONS\n",
        "\n",
        "    # Set up weights for weighted sum of ReLUs\n",
        "    combination_weights = torch.zeros((n_relus, ))\n",
        "\n",
        "    # Figure out weights on each ReLU\n",
        "    prev_slope = 0\n",
        "    for i in range(n_relus):\n",
        "      delta_x = x_train[i+1] - x_train[i]\n",
        "      slope = (y_train[i+1] - y_train[i]) / delta_x \n",
        "      combination_weights[i] = slope - prev_slope\n",
        "      prev_slope = slope\n",
        "\n",
        "    # Get output of weighted sum of ReLU activations for every point along x axis\n",
        "    y_hat = combination_weights @ relu_acts \n",
        "\n",
        "    return y_hat, relu_acts, x\n",
        "\n",
        "# Make training data from sine function\n",
        "N_train = 10\n",
        "x_train = torch.linspace(0, 2*np.pi, N_train).view(-1, 1)\n",
        "y_train = torch.sin(x_train)\n",
        "\n",
        "\n",
        "### uncomment the lines below to test your function approximation\n",
        "y_hat, relu_acts, x = approximate_function(x_train, y_train)\n",
        "with plt.xkcd():\n",
        "  plot_function_approximation(x, relu_acts, y_hat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b37WDpWIUNU"
      },
      "source": [
        "---\n",
        "# Section 3: MLPs in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it4t-UVzJeop",
        "cellView": "form"
      },
      "source": [
        "#@title Video 3: Making Multi-Layer Perceptrons\n",
        "# Insert the ID of the corresponding youtube video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"bAhrg8Z8_r8\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtu.be/\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XadSdjL2qWj"
      },
      "source": [
        "In the previous segment, we implemented a function to approximate any smooth function using MLPs. We saw that using Lipschitz continuity; we can prove that our approximation is mathematically correct. MLPs are fascinating, but before we get into the details on designing them, let's familiarize ourselves with some basic terminology of MLPs- layer, neuron, depth, width, weight, bias, and activation function. Armed with these ideas, we can now design an MLP given its input, hidden layers, and output size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_TpUE0cHW1K"
      },
      "source": [
        "## Exercise 2: Implement a general-purpose MLP in Pytorch\n",
        "The objective is to design an MLP with these properties:\n",
        "* works with any input (1D, 2D, etc.)\n",
        "* construct any number of given hidden layers using ModuleList\n",
        "* use the same given activation function in all hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsq7SdqHx8a"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, actv, num_inputs, hidden_units, num_outputs):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Assign activation function (exec allows us to assign function from string)\n",
        "        exec('self.actv = nn.%s'%actv)  \n",
        "\n",
        "        # Initialize layers of MLP\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        ####################################################################\n",
        "        # Fill in missing code below (...),\n",
        "        # then remove or comment the line below to test your function\n",
        "        raise NotImplementedError(\"Create MLP Layers\")\n",
        "        ####################################################################\n",
        "\n",
        "        # Loop over layers and create each one\n",
        "        for i in range(len(hidden_units)):\n",
        "          next_num_inputs = hidden_units[i] \n",
        "          self.layers += ...\n",
        "          num_inputs = next_num_inputs\n",
        "\n",
        "        # Create final layer\n",
        "        self.out = nn.Linear(num_inputs, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ####################################################################\n",
        "        # Fill in missing code below (...),\n",
        "        # then remove or comment the line below to test your function\n",
        "        raise NotImplementedError(\"Calculate the forward pass\")\n",
        "        ####################################################################\n",
        "\n",
        "        # Flatten inputs to 2D (if more than that)\n",
        "        x = ...\n",
        "\n",
        "        # Get activations of each layer\n",
        "        for layer in self.layers:\n",
        "          x = ...\n",
        "\n",
        "        # Get outputs\n",
        "        x = self.out(x) \n",
        "\n",
        "        return x\n",
        "\n",
        "### Uncomment below to create network and test it on input\n",
        "# net = Net(actv='LeakyReLU(0.1)',\n",
        "#     num_inputs = 2,\n",
        "#     hidden_units = [100, 10, 5],\n",
        "#     num_outputs = 1)\n",
        "\n",
        "# input = torch.zeros((100, 2))\n",
        "# y = net(input)\n",
        "# print(f'The output shape is {y.shape} for an input of shape {input.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12yuLUsp3v0J"
      },
      "source": [
        "# to_remove solution\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, actv, num_inputs, hidden_units, num_outputs):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Assign activation function (exec allows us to assign function from string)\n",
        "        exec('self.actv = nn.%s'%actv)  \n",
        "\n",
        "        # Initialize layers of MLP\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # Loop over layers and create each one\n",
        "        for i in range(len(hidden_units)):\n",
        "          next_num_inputs = hidden_units[i] \n",
        "          self.layers += [nn.Linear(num_inputs, next_num_inputs)]  \n",
        "          num_inputs = next_num_inputs\n",
        "\n",
        "        # Create final layer\n",
        "        self.out = nn.Linear(num_inputs, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Flatten inputs to 2D (if more than that)\n",
        "        x = x.view(x.shape[0], -1)  \n",
        "\n",
        "        # Get activations of each layer\n",
        "        for layer in self.layers:\n",
        "          x = self.actv(layer(x))  \n",
        "\n",
        "        # Get outputs\n",
        "        x = self.out(x) \n",
        "\n",
        "        return x\n",
        "\n",
        "### Uncomment below to create network and test it on input\n",
        "net = Net(actv='LeakyReLU(0.1)',\n",
        "    num_inputs = 2,\n",
        "    hidden_units = [100, 10, 5],\n",
        "    num_outputs = 1)\n",
        "\n",
        "input = torch.zeros((100, 2))\n",
        "y = net(input)\n",
        "print(f'The output shape is {y.shape} for an input of shape {input.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VDVqxxaJlz8"
      },
      "source": [
        "## Section 3.1: Classification with MLPs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXlMu7ouaKrb",
        "cellView": "form"
      },
      "source": [
        "#@title Video 3.1: Classification and CrossEntropy\n",
        "# Insert the ID of the corresponding youtube video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"bxzDe2pifKU\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtu.be/\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meZhRHa14_KM"
      },
      "source": [
        "Two potential loss functions we could use out of the box for multi-class classification are:\n",
        "* CrossEntropyLoss:\n",
        "This criterion expects a class index in the range $[0, C-1]$ as the target (labels) for each value of a $1D$ tensor of size minibatch (`N`). There are other optional parameters like class weights and class ignores. Check the documentation here for more detail. \n",
        "\n",
        "To get CrossEntropyLoss of a sample $i$, we could first calculate $-\\log(\\text{softmax(x}))$ and then take the element corresponding to $\\text { label }_i$ as the loss. However, due to numerical stability, we implement this more stable equivalent form,\n",
        "\n",
        "$$\n",
        "\\operatorname{loss}(x_i, \\text { label }_i)=-\\log \\left(\\frac{\\exp (x[\\text { label }_i])}{\\sum_{j} \\exp (x[j])}\\right)=-x_i[\\text { label }_i]+\\log \\left(\\sum_{j=1}^C \\exp (x_i[j])\\right)\n",
        "$$\n",
        "\n",
        "* MultiMarginLoss: as a bonus you could see bellow cell for implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMb56P7ZweTX"
      },
      "source": [
        "## Bonus: Multi Margin Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q11Uhie1wf-"
      },
      "source": [
        "The loss corresponding to class j is calculated as follows,\n",
        "$$\n",
        "l_j(x, label)=\\sum_{j\\neq label} \\max (0, \\operatorname{margin}-x[label]+x[j])\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cfm-7rKyWk7"
      },
      "source": [
        "## Exercise 3: Implement Batch Cross Entropy Loss\n",
        "\n",
        "Since we will be doing batch learning, we'd like a loss function that given:\n",
        "* a batch of predidictions `x` with shape `(N, C)` \n",
        "* a batch of `labels` with shape `(N, )` that ranges from `0` to `C-1`\n",
        "\n",
        "returns the average loss $L$ calculated according to:\n",
        "$$\n",
        "loss(x_i, \\text { label }_i)=-x_i[\\text { label }_i]+\\log \\left(\\sum_{j=1}^C \\exp (x_i[j])\\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "L = \\frac{1}{N} \\sum_{i=1}^{N}{loss(x_i, \\text { label }_i)}\n",
        "$$\n",
        "\n",
        "Steps:\n",
        "\n",
        "1.   Use indexing operation to get predictions of class corresponding to the labels (i.e., $x_i[\\text { label }_i]$)\n",
        "2.   Compute $loss(x_i, \\text { label }_i)$ vector (`losses`) using `torch.log()` and `torch.exp()` without Loops!\n",
        "3. Return the average of the loss vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OkPBujqWy74"
      },
      "source": [
        "def cross_entropy_loss(x, labels):\n",
        "  ####################################################################\n",
        "  # Fill in missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Cross Entropy Loss\")\n",
        "  ####################################################################\n",
        "\n",
        "  x_of_labels = torch.zeros(len(labels))\n",
        "  for i, label in enumerate(labels):\n",
        "    # 1. prediction for each class corresponding to the label\n",
        "    x_of_labels[i] = ...\n",
        "\n",
        "  # 2. loss vector for the batch\n",
        "  losses = ...\n",
        "\n",
        "  # 3. Return the average of the loss vector\n",
        "  avg_loss = ...\n",
        "  \n",
        "  return avg_loss\n",
        "\n",
        "### Uncomment below to test your function\n",
        "# labels = torch.tensor([0, \n",
        "#                        1])\n",
        "# x = torch.tensor([[10.0, 1.0, -1.0, -20.0], # correctly classified\n",
        "#                   [10.0, 10.0, 85.0, -110.0]]) # Not correctly classified\n",
        "\n",
        "# our_loss = cross_entropy_loss(x, labels).item()\n",
        "\n",
        "# CE = nn.CrossEntropyLoss()\n",
        "# pytorch_loss = CE(x, labels).item()\n",
        "# print('Our CE loss: %0.8f, Pytorch CE loss: %0.8f'%(our_loss, pytorch_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCdz8gwHh-C_"
      },
      "source": [
        "# to_remove solution\n",
        "\n",
        "def cross_entropy_loss(x, labels):\n",
        "  \n",
        "  x_of_labels = torch.zeros(len(labels))\n",
        "  for i, label in enumerate(labels):\n",
        "    # 1. prediction for each class corresponding to the label\n",
        "    x_of_labels[i] = x[i, label]\n",
        "\n",
        "  # 2. loss vector for the batch\n",
        "  losses = -x_of_labels + torch.log(torch.sum(torch.exp(x), axis=1))\n",
        "\n",
        "  # 3. Return the average of the loss vector\n",
        "  avg_loss = losses.mean()\n",
        "\n",
        "  return avg_loss\n",
        "\n",
        "### Uncomment below to test your function\n",
        "labels = torch.tensor([0, \n",
        "                       1])\n",
        "x = torch.tensor([[10.0, 1.0, -1.0, -20.0], # correctly classified\n",
        "                  [10.0, 10.0, 100.0, -110.0]]) # Not correctly classified\n",
        "\n",
        "our_loss = cross_entropy_loss(x, labels).item()\n",
        "\n",
        "CE = nn.CrossEntropyLoss()\n",
        "pytorch_loss = CE(x, labels).item()\n",
        "print('Our CE loss: %0.8f, Pytorch CE loss: %0.8f'%(our_loss, pytorch_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCvA5etP2GOy"
      },
      "source": [
        "## Section 3.2: Spiral classification dataset\n",
        "Before we could start optimizing these loss functions, we need a dataset!\n",
        "\n",
        "Let's turn this fancy-looking equation into a classification dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTdmdB6oD0KU"
      },
      "source": [
        "$$\n",
        "\\begin{array}{c}\n",
        "X_{k}(t)=t\\left(\\begin{array}{c}\n",
        "\\sin \\left[\\frac{2 \\pi}{K}\\left(2 t+k-1\\right)\\right]+\\mathcal{N}\\left(0, \\sigma\\right) \\\\\n",
        "\\cos \\left[\\frac{2 \\pi}{K}\\left(2 t+k-1\\right)\\right]+\\mathcal{N}\\left(0, \\sigma\\right) \n",
        "\\end{array}\\right)\n",
        "\\end{array}, \\quad 0 \\leq t \\leq 1, \\quad k=1, \\ldots, K\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA7lYMIW6c6e"
      },
      "source": [
        "# to_remove solution\n",
        "def create_spiral_dataset(K, sigma, N):\n",
        "\n",
        "    # Initialize t, X, y\n",
        "    t = torch.linspace(0, 1, N)\n",
        "    X = torch.zeros(K*N, 2)\n",
        "    y = torch.zeros(K*N)\n",
        "\n",
        "    # Create data\n",
        "    for k in range(K):\n",
        "      X[k*N:(k+1)*N, 0] = t*(torch.sin(2*np.pi/K*(2*t+k)) + sigma*torch.randn(N))   \n",
        "      X[k*N:(k+1)*N, 1] = t*(torch.cos(2*np.pi/K*(2*t+k)) + sigma*torch.randn(N))   \n",
        "      y[k*N:(k+1)*N] = k   \n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Set parameters\n",
        "K = 4\n",
        "sigma = 0.16\n",
        "N = 1000\n",
        " \n",
        "### Uncomment below to visualize data when done\n",
        "X, y = create_spiral_dataset(K, sigma, N)\n",
        "with plt.xkcd():\n",
        "  plt.scatter(X[:, 0], X[:, 1], c = y)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUhAlD-XcbTa"
      },
      "source": [
        "## Section 3.3: Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY2VN0MfcSPN",
        "cellView": "form"
      },
      "source": [
        "#@title Video 3.3: Cross-Validation\n",
        "# Insert the ID of the corresponding youtube video\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"U6BFrVCLsWU\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtu.be/\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3RZa-charD2"
      },
      "source": [
        "## Exercise 4: Implement it for a classfication task\n",
        "Now that we have the Spiral dataset and loss function, it's your turn to implement a simple train/test split for training and validation.\n",
        "\n",
        "Steps to follow: \n",
        "  * Dataset shuffle\n",
        "  * Train/Test split\n",
        "  * Dataloader definition\n",
        "  * Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCS2dEqPfiA"
      },
      "source": [
        "def shuffle_and_split_data(X, y):\n",
        "\n",
        "  ####################################################################\n",
        "  # Fill in missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Shuffle & split data\")\n",
        "  ####################################################################\n",
        "\n",
        "  # Number of samples\n",
        "  N = X.shape[0]\n",
        "\n",
        "  # Shuffle data\n",
        "  shuffled_indices = ...  # get indices to shuffle data\n",
        "  X = X[shuffled_indices]\n",
        "  y = y[shuffled_indices]\n",
        "\n",
        "  # Split data into train/test\n",
        "  test_size = ...  # assign size of test data\n",
        "  X_test = X[:test_size]\n",
        "  y_test = y[:test_size]\n",
        "  X_train = X[test_size:]\n",
        "  y_train = y[test_size:]\n",
        "\n",
        "  return X_test, y_test, X_train, y_train\n",
        "\n",
        "\n",
        "### Uncomment below to test your function\n",
        "# X_test, y_test, X_train, y_train = shuffle_and_split_data(X, y)\n",
        "# plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
        "# plt.title('Test data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymb3r0pM6665"
      },
      "source": [
        "# to_remove solution\n",
        "def shuffle_and_split_data(X, y):\n",
        "\n",
        "  # Number of samples\n",
        "  N = X.shape[0]\n",
        "\n",
        "  # Shuffle data\n",
        "  shuffled_indices = torch.randperm(N)   # get indices to shuffle data\n",
        "  X = X[shuffled_indices]\n",
        "  y = y[shuffled_indices]\n",
        "\n",
        "  # Split data into train/test\n",
        "  test_size = int(0.2*N)    # assign size of test data\n",
        "  X_test = X[:test_size]\n",
        "  y_test = y[:test_size]\n",
        "  X_train = X[test_size:]\n",
        "  y_train = y[test_size:]\n",
        "\n",
        "  return X_test, y_test, X_train, y_train\n",
        "\n",
        "\n",
        "\n",
        "X_test, y_test, X_train, y_train = shuffle_and_split_data(X, y)\n",
        "with plt.xkcd():\n",
        "  plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
        "  plt.title('Test data')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMYnhid1bCyq"
      },
      "source": [
        "And we need to make a Pytorch data loader out of it. Data loading in PyTorch can be separated in 2 parts:\n",
        "* Data must be wrapped on a Dataset parent class where the methods __getitem__ and __len__ must be overrided. Not that at this point the data is not loaded on memory. PyTorch will only load what is needed to the memory. Here `TensorDataset` does this for us directly.\n",
        "* Use a Dataloader that will actually read the data in batches and put into memory. Also, the option of `num_workers > 0` allows multithreading, which prepares multiple batches in the queue to speed things up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPJNQtOOgC3E"
      },
      "source": [
        "batch_size = 128\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
        "                         shuffle=False, num_workers=0)\n",
        "\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, drop_last=True,\n",
        "                        shuffle=True, num_workers=0, worker_init_fn=seed_worker)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyRvSvQ8AJzk"
      },
      "source": [
        "Let's write a general-purpose training and evaluation code and keep it in our pocket for next tutorial as well. So make sure you review it to see what it does.\n",
        "\n",
        "Note that `model.train()` tells your model that you are training the model. So effectively layers like dropout, batchnorm etc. which behave different on the train and test procedures know what is going on and hence can behave accordingly. And to turn off training mode we set `model.eval()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW95_EQp1QHx"
      },
      "source": [
        "def train_test_classification(net, criterion, optimizer,\n",
        "                              train_loader, test_loader,\n",
        "                              num_epochs=1, verbose=True, \n",
        "                              training_plot=False):\n",
        "  if verbose:\n",
        "    progress_bar = display(progress(0, 0, num_epochs), display_id=True)\n",
        "\n",
        "  net.train()\n",
        "  training_losses = []\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(dev).float()\n",
        "          labels = labels.to(dev).long()\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          if verbose:\n",
        "            training_losses += [loss.item()]\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:    # update every 10 mini-batches\n",
        "                progress_bar.update(progress(epoch+1, running_loss / 10, num_epochs))\n",
        "                running_loss = 0.0\n",
        "\n",
        "  net.eval()\n",
        "  def test(data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in data_loader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(dev).float()\n",
        "        labels = labels.to(dev).long()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    return total, acc\n",
        "\n",
        "  train_total, train_acc = test(train_loader)\n",
        "  test_total, test_acc = test(test_loader)\n",
        "\n",
        "  if verbose:\n",
        "    print('Accuracy on the %d training samples: %0.2f %%' % (train_total, train_acc))\n",
        "    print('Accuracy on the %d testing samples: %0.2f %%' % (test_total, test_acc))\n",
        "\n",
        "  if training_plot:\n",
        "    plt.plot(training_losses)\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Training loss')\n",
        "    plt.show()\n",
        "  \n",
        "  return train_acc, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "UX-BvX_qBJl6"
      },
      "source": [
        "#@markdown Is it necessary to use `net.train()` and `net.eval()` for our MLP model? why?\n",
        "w3_why_two_modes = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-g2TXrC_TOQ"
      },
      "source": [
        "Now let's put everything together and train your first deep-ish model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEGwbZrUfpZu"
      },
      "source": [
        "net = Net('ReLU()', X_train.shape[1], [128], K).to(dev)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "num_epochs = 100\n",
        "_, _ = train_test_classification(net, criterion, optimizer, train_loader,\n",
        "                                 test_loader, num_epochs=num_epochs,\n",
        "                                 training_plot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_HvMx0thX42"
      },
      "source": [
        "And finally, let's visualize the learned decision-map. We know you're probably running out of time, so we won't make you write code now! But make sure you have reviewed it since we'll start with another visualization technique next time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elWAOswugLak"
      },
      "source": [
        "def sample_grid(M=500, x_max = 2.0):\n",
        "  ii, jj = torch.meshgrid(torch.linspace(-x_max, x_max,M),\n",
        "                          torch.linspace(-x_max, x_max, M))\n",
        "  X_all = torch.cat([ii.unsqueeze(-1),\n",
        "                     jj.unsqueeze(-1)],\n",
        "                     dim=-1).view(-1, 2)\n",
        "  return X_all\n",
        "\n",
        "def plot_decision_map(X_all, y_pred, X_test, y_test, M=500, x_max = 2.0, eps = 1e-3):\n",
        "  decision_map = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "  for i in range(len(X_test)):\n",
        "    indeces = (X_all[:, 0] - X_test[i, 0])**2 + (X_all[:, 1] - X_test[i, 1])**2 < eps\n",
        "    decision_map[indeces] = (K + y_test[i]).long()\n",
        "\n",
        "  decision_map = decision_map.view(M, M).cpu()\n",
        "  plt.imshow(decision_map, extent=[-x_max, x_max, -x_max, x_max], cmap='jet')\n",
        "  plt.plot()\n",
        "\n",
        "X_all = sample_grid()\n",
        "y_pred = net(X_all)\n",
        "plot_decision_map(X_all, y_pred, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "VpVW1MjDCToL"
      },
      "source": [
        "#@markdown Do you think this model is performing well outside its training distribution? Why?\n",
        "w3_OoD = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31mPmt3bYS5H"
      },
      "source": [
        "# Submit your responses\n",
        "Please run the following cell and then press \"Submit\" so we can record your responses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T0vbGaHYXtC",
        "cellView": "form"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from IPython.display import IFrame\n",
        "#@markdown #Run Cell to Show Airtable Form\n",
        "#@markdown ##**Confirm your answers and then click \"Submit\"**\n",
        "\n",
        "def prefill_form(src, fields: dict):\n",
        "  '''\n",
        "  src: the original src url to embed the form\n",
        "  fields: a dictionary of field:value pairs,\n",
        "  e.g. {\"pennkey\": my_pennkey, \"location\": my_location}\n",
        "  '''\n",
        "  prefills = \"&\".join([\"prefill_%s=%s\"%(key, fields[key]) for key in fields])\n",
        "  src = src + prefills\n",
        "  src = \"+\".join(src.split(\" \"))\n",
        "  return src\n",
        "\n",
        "\n",
        "#autofill time if it is not present\n",
        "try: t0;\n",
        "except NameError: t0 = time.time()\n",
        "try: t1;\n",
        "except NameError: t1 = time.time()\n",
        "try: t2;\n",
        "except NameError: t2 = time.time()\n",
        "try: t3;\n",
        "except NameError: t3 = time.time()\n",
        "\n",
        "#autofill fields if they are not present\n",
        "#a missing pennkey and pod will result in an Airtable warning\n",
        "#which is easily fixed user-side.\n",
        "try: my_pennkey;\n",
        "except NameError: my_pennkey = \"\"\n",
        "\n",
        "try: my_pod;\n",
        "except NameError: my_pod = \"Select\"\n",
        "\n",
        "try: w2_upshot;\n",
        "except NameError: w2_upshot = \"\"\n",
        "\n",
        "try: w3_q;\n",
        "except NameError: w3_q = \"\"\n",
        "\n",
        "try: w3_min_xor;\n",
        "except NameError: w3_min_xor = \"\"\n",
        "\n",
        "try: w3_why_become_relu;\n",
        "except NameError: w3_why_become_relu = \"\"\n",
        "\n",
        "try: w3_why_two_modes;\n",
        "except NameError: w3_why_two_modes = \"\"\n",
        "\n",
        "try: w3_OoD;\n",
        "except NameError: w3_OoD = \"\"\n",
        "\n",
        "\n",
        "times = np.array([t1,t2,t3])-t0\n",
        "\n",
        "fields = {\"pennkey\": my_pennkey,\n",
        "          \"pod\": my_pod,\n",
        "          \"w2_upshot\":w2_upshot,\n",
        "          \"w3_q\": w3_q,\n",
        "          \"w3_why_become_relu\":w3_why_become_relu,\n",
        "          \"w3_min_xor\": w3_min_xor,\n",
        "          \"w3_why_two_modes\":w3_why_two_modes,\n",
        "          \"w3_OoD\":w3_OoD,\n",
        "          \"cumulative_times\": times}\n",
        "\n",
        "src = \"https://airtable.com/embed/shrO0aY7Sz8u8qY2H?\"\n",
        "\n",
        "#now instead of the original source url, we do: src = prefill_form(src, fields)\n",
        "display(IFrame(src = prefill_form(src, fields), width = 800, height = 400))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhhpq4gvanhu"
      },
      "source": [
        "## Feedback\n",
        "How could this session have been better? How happy are you in your group? How do you feel right now?\n",
        "\n",
        "Feel free to use the embeded form below or use this link:\n",
        "<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://airtable.com/shrNSJ5ECXhNhsYss\">https://airtable.com/shrNSJ5ECXhNhsYss</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "NQ3oX2LFa3AB"
      },
      "source": [
        "# @title Feedback form\n",
        "display(IFrame(src=\"https://airtable.com/embed/shrNSJ5ECXhNhsYss?backgroundColor=red\", width = 800, height = 400))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}